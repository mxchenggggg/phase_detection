{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "459b4fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import re\n",
    "import click\n",
    "import logging\n",
    "from rich.logging import RichHandler\n",
    "from rich.progress import track\n",
    "import json\n",
    "import shutil\n",
    "import queue\n",
    "import threading\n",
    "q=queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Receive():\n",
    "    print(\"start Reveive\")\n",
    "    cap = cv2.VideoCapture(\"rtsp://admin:admin_123@172.0.0.0\")\n",
    "    ret, frame = cap.read()\n",
    "    q.put(frame)\n",
    "    while ret:\n",
    "        ret, frame = cap.read()\n",
    "        q.put(frame)\n",
    "\n",
    "\n",
    "def Display():\n",
    "     print(\"Start Displaying\")\n",
    "     while True:\n",
    "         if q.empty() !=True:\n",
    "            frame=q.get()\n",
    "            cv2.imshow(\"frame1\", frame)\n",
    "         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "if __name__=='__main__':\n",
    "    p1=threading.Thread(target=Receive)\n",
    "    p2 = threading.Thread(target=Display)\n",
    "    p1.start()\n",
    "    p2.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4488553",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAT = \"%(message)s\"\n",
    "logging.basicConfig(\n",
    "    level=\"DEBUG\",\n",
    "    format=FORMAT,\n",
    "    datefmt=\"[%X]\",\n",
    "    handlers=[RichHandler(rich_tracebacks=True)],\n",
    ")\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ddfa490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:52:32] </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Need to process <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'V001'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'V003'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'V002'</span><span style=\"font-weight: bold\">]</span>                 <a href=\"file:///var/folders/wc/zvvkqrnx2t1dmlgms29_9pqh0000gn/T/ipykernel_71247/2929820891.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2929820891.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/wc/zvvkqrnx2t1dmlgms29_9pqh0000gn/T/ipykernel_71247/2929820891.py#30\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:52:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Need to process \u001b[1m[\u001b[0m\u001b[32m'V001'\u001b[0m, \u001b[32m'V003'\u001b[0m, \u001b[32m'V002'\u001b[0m\u001b[1m]\u001b[0m                 \u001b]8;id=985544;file:///var/folders/wc/zvvkqrnx2t1dmlgms29_9pqh0000gn/T/ipykernel_71247/2929820891.py\u001b\\\u001b[2m2929820891.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=266526;file:///var/folders/wc/zvvkqrnx2t1dmlgms29_9pqh0000gn/T/ipykernel_71247/2929820891.py#30\u001b\\\u001b[2m30\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_root = \"/Users/kevinlawk/Documents/PhaseSeg/data_preprocessing/mastoid/\"\n",
    "output_root = \"/Users/kevinlawk/Documents/PhaseSeg/data_preprocessing/mastoid_dataset/\"\n",
    "width = 100\n",
    "height = 100\n",
    "\n",
    "\n",
    "\n",
    "# Check if the data root exist\n",
    "if not os.path.exists(data_root):\n",
    "    raise Exception(\"Data root does not exist\")\n",
    "\n",
    "# Check if such directory exist or not\n",
    "if not os.path.isdir(output_root):\n",
    "    os.makedirs(output_root)\n",
    "\n",
    "# Check what videos we have in the output root\n",
    "existing_videos = [\n",
    "    tmp for tmp in os.listdir(output_root) if re.match(\"[V][0-9]+\", tmp) is not None\n",
    "]\n",
    "existing_videos = []\n",
    "# Fetch the videos that are needed to be preprocessed\n",
    "videos_to_process = [\n",
    "    tmp\n",
    "    for tmp in os.listdir(data_root)\n",
    "    if re.match(\"[V][0-9]+\", tmp) is not None and tmp not in existing_videos\n",
    "]\n",
    "# if config:\n",
    "#     videos_to_process = [f\"V{i:03d}\" for i in config_pre[\"idx\"]]\n",
    "\n",
    "log.debug(f\"Need to process {videos_to_process}\")\n",
    "# Create a frame dictonary\n",
    "frame_dict = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc901250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/kevinlawk/Documents/PhaseSeg/data_preprocessing/mastoid/V001/V001_part1.mp4',\n",
       " '/Users/kevinlawk/Documents/PhaseSeg/data_preprocessing/mastoid/V001/V001_part2.mp4']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_files[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed8cf6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV(4.5.5) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "2\n",
      "OpenCV(4.5.5) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q.queue.clear()\n",
    "t1 = threading.Thread(target=fetch_video_frame, args=[video_files[0:2], start_frame])\n",
    "t2 = threading.Thread(target=process_video_frame, args=[annotation, width, height, start_frame, end_frame, output_root, video_set])\n",
    "t1.start()\n",
    "t2.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5471bb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinlawk/.pyenv/versions/3.7.9/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3532: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "44ca7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_video_frame(video_files, start_frame):\n",
    "    video_files.sort()\n",
    "    for idx, video in enumerate(video_files):\n",
    "        cap = cv2.VideoCapture(video)\n",
    "        # Trim the starting part\n",
    "        if idx == 1:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        ret, frame = cap.read()\n",
    "        q.put(frame)\n",
    "        while cap.isOpened() and ret:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                q.put(frame)\n",
    "\n",
    "def process_video_frame(annotation, width, height, start_frame, end_frame, output_root, video_set):\n",
    "    frame_df = {}\n",
    "    curr_frame = 0\n",
    "    while curr_frame <= (end_frame - start_frame):\n",
    "        if q.empty():\n",
    "            continue\n",
    "        # Fetch the frame from queue\n",
    "        frame=q.get()\n",
    "        curr_frame += 1\n",
    "        # Resize the image\n",
    "#         frame = center_crop(frame,(1080,1080))\n",
    "        try:\n",
    "            frame = cv2.resize(frame, (int(width), int(height)), cv2.INTER_AREA)\n",
    "            # Save the frame\n",
    "            frame_path = os.path.join(\n",
    "                output_root, video_set, f\"{video_set}_{curr_frame}.png\"\n",
    "            )\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            print(curr_frame)\n",
    "        # Search for the corrsponding label\n",
    "        label_df = annotation[\n",
    "            annotation[\"Frame start\"] <= curr_frame + start_frame\n",
    "        ].iloc[-1]\n",
    "        frame_step = label_df[\"Step\"]\n",
    "        frame_task = label_df[\"Task\"]\n",
    "        frame_dict[curr_frame] = [\n",
    "            curr_frame,\n",
    "            frame_step,\n",
    "            frame_task,\n",
    "            frame_path,\n",
    "        ]\n",
    "        \n",
    "    frame_df = pd.DataFrame.from_dict(\n",
    "        frame_dict, orient=\"index\", columns=[\"Frame\", \"Step\", \"Task\", \"Img_Path\"]\n",
    "    )\n",
    "    frame_df.to_csv(\n",
    "        os.path.join(output_root, video_set, f\"{video_set}_annotation.csv\"), index=False\n",
    "    )\n",
    "    print(\"Done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7f27e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_set = \"V001\"\n",
    "if os.path.exists(os.path.join(output_root, video_set)) and os.path.isdir(os.path.join(output_root, video_set)):\n",
    "    shutil.rmtree(os.path.join(output_root, video_set))\n",
    "# Create the directory for videos in output root\n",
    "os.makedirs(os.path.join(output_root, video_set))\n",
    "# Fetch the video set path in data root\n",
    "video_set_path = os.path.join(data_root, video_set)\n",
    "# Convert the xlsx file into csv format\n",
    "xlxs_file_path = os.path.join(\n",
    "    video_set_path, f\"{video_set}_annotated.xlsx\")\n",
    "annotation = pd.read_excel(xlxs_file_path, engine=\"openpyxl\")\n",
    "# Fetch the start and end frame\n",
    "start_frame = annotation.iloc[0][\"Frame start\"]\n",
    "# start_frame = 10\n",
    "end_frame = annotation.iloc[-1][\"Frame end\"]\n",
    "# end_frame = 1500\n",
    "# Fetch the videos to be processed\n",
    "video_files = [\n",
    "    tmp\n",
    "    for tmp in os.listdir(video_set_path)\n",
    "    if re.match(f\"{video_set}_part[0-9]+.[mp4|MP4]\", tmp) is not None\n",
    "]\n",
    "\n",
    "video_files.sort()\n",
    "curr_frame = 0\n",
    "video_files = [os.path.join(video_set_path, tmp) for tmp in video_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "87226b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/kevinlawk/Documents/PhaseSeg/data_preprocessing/mastoid/V001/V001_part1.mp4',\n",
       " '/Users/kevinlawk/Documents/PhaseSeg/data_preprocessing/mastoid/V001/V001_part2.mp4',\n",
       " '/Users/kevinlawk/Documents/PhaseSeg/data_preprocessing/mastoid/V001/V001_part3.mp4']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8dd518a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba659531",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Preprocess the video\n",
    "for video_set in track(videos_to_process, f\"Processing Now ...\"):\n",
    "    log.debug(f\"************ Start processing {video_set} ************\")\n",
    "\n",
    "    # if the output dir exsists, remove it\n",
    "    if os.path.exists(os.path.join(output_root, video_set)) and os.path.isdir(os.path.join(output_root, video_set)):\n",
    "        shutil.rmtree(os.path.join(output_root, video_set))\n",
    "    # Create the directory for videos in output root\n",
    "    os.makedirs(os.path.join(output_root, video_set))\n",
    "    # Fetch the video set path in data root\n",
    "    video_set_path = os.path.join(data_root, video_set)\n",
    "    # Convert the xlsx file into csv format\n",
    "    xlxs_file_path = os.path.join(\n",
    "        video_set_path, f\"{video_set}_annotated.xlsx\")\n",
    "    annotation = pd.read_excel(xlxs_file_path, engine=\"openpyxl\")\n",
    "    # Fetch the start and end frame\n",
    "    start_frame = annotation.iloc[0][\"Frame start\"]\n",
    "    # start_frame = 10\n",
    "    end_frame = annotation.iloc[-1][\"Frame end\"]\n",
    "    # end_frame = 1500\n",
    "    # Fetch the videos to be processed\n",
    "    video_files = [\n",
    "        tmp\n",
    "        for tmp in os.listdir(video_set_path)\n",
    "        if re.match(f\"{video_set}_part[0-9]+.[mp4|MP4]\", tmp) is not None\n",
    "    ]\n",
    "\n",
    "    video_files.sort()\n",
    "    curr_frame = 0\n",
    "    video_files = [os.path.join(video_set_path, tmp) for tmp in video_files]\n",
    "    for idx, video in enumerate(video_files):\n",
    "        # Open the Video\n",
    "        cap = cv2.VideoCapture(os.path.join(video_set_path, video))\n",
    "        # Trim the starting part\n",
    "        if idx == 1:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        # Loop the video\n",
    "        while cap.isOpened() and curr_frame <= (end_frame - start_frame):\n",
    "            # Read the video\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                log.debug(\n",
    "                    f\"Current Frame is {curr_frame} \\n Can't receive frame (stream end). Going to next video ...\"\n",
    "                )\n",
    "                break\n",
    "            # frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            curr_frame += 1\n",
    "            # Resize the image\n",
    "            frame = center_crop(frame,(1080,1080))\n",
    "            frame = cv2.resize(frame, (int(width), int(height)), cv2.INTER_AREA)\n",
    "            # Save the frame\n",
    "            frame_path = os.path.join(\n",
    "                output_root, video_set, f\"{video_set}_{curr_frame}.png\"\n",
    "            )\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            # Search for the corrsponding label\n",
    "            label_df = annotation[\n",
    "                annotation[\"Frame start\"] <= curr_frame + start_frame\n",
    "            ].iloc[-1]\n",
    "            frame_step = label_df[\"Step\"]\n",
    "            frame_task = label_df[\"Task\"]\n",
    "            frame_dict[curr_frame] = [\n",
    "                curr_frame,\n",
    "                frame_step,\n",
    "                frame_task,\n",
    "                frame_path,\n",
    "            ]\n",
    "\n",
    "    frame_df = pd.DataFrame.from_dict(\n",
    "        frame_dict, orient=\"index\", columns=[\"Frame\", \"Step\", \"Task\", \"Img_Path\"]\n",
    "    )\n",
    "    frame_df.to_csv(\n",
    "        os.path.join(output_root, video_set, f\"{video_set}_annotation.csv\"), index=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
