\documentclass[11pt]{article} \usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{amsfonts, amsmath, amssymb, amsthm}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage[british,calc]{datetime2}
\usepackage{advdate}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{float}
\bibliographystyle{ieeetr}

\title{Surgical Phase Detection Using Deep Learning\\ Critical Review}
\author{Xiaorui Zhang, Wenkai Luo, Xucheng Ma}
\date{March 2022}

\begin{document}
\maketitle
\section{Project Problem Statement \& Background}
Our project focuses on developing Deep Learning models which perform mastoidectomy video segmentation. The model \textbf{inputs} is a sequence of frames, and model \textbf{output} is a sequence of surgical phase labels. The main technical problems we need to solve is how to design an efficient and robust feature extractor for surgical videos, then we can perform classification in the feature space to obtain phase labels.

\vspace{0.25cm}
\noindent
In general surgical phase segmentation workflow, both \textbf{spatial} features and \textbf{temporal} features are often considered, e.g.
\begin{itemize}
  \item Spatial Features: anatomical structures, tool presence/positioning ...
  \item Temporal Features: anatomical changes, tool movement, camera view changes​ ...
\end{itemize}
Mastoidectomy videos has some characteristic features:
\begin{itemize}
  \item Anatomical features are mostly \textbf{rigid} since is a skull based surgery. 
  \item Anatomical changes are mostly in depth direction as the overall surgery process is exposing the interior structures behind patient's ear.
  \item Camera view changes might imply transition between surgical phases.
  \item Tool positioning may contain more useful information about correct phase label than tool presence, because main tools involved are only drill and suction device and the are used across whole procedure.
\end{itemize}

\vspace{0.25cm}
\noindent
Typical DL methods for surgical phase segmentation has following components:
\begin{itemize}
  \item Spatial Feature Extractor
  \item Temporal Feature Extractor
  \item Spatial-Temporal Feature Fusion
  \item Classifier in Feature Space
\end{itemize}
Papers which we included in this review are all consisted of components above, but different approaches were chosen for each component. For each paper, we first introduce the problem that the specific network design aimed to address, then summarize the main contributions, and discuss key results and potential problems.

\section{Critical Review of SV-RCNet}
\begin{itemize}
    \item \textit{Background and problems with prior works:}\\
    The automatic surgical video segmentation is a fundamental component in building a context-awareness computer-aided surgery system.  Before this work, several Vision-Based and Deep Learning oriented methods were proposed to extract spatial and temporal features and train a classifier to perform the segmentation task. However, there are three main drawbacks to the previous works.  First, the previously used visual features, either hand-crafted or shallow CNN-based, are still far from sufficient to represent the complicated visual characteristics of the frames in surgical videos. In addition, when exploiting the temporal information, most traditional methods rely on linear statistical models with pre-defined dependencies, which are incapable of precisely representing motions in the surgical videos, especially for frame series with strong non-linear dynamics. Second, and more importantly, most existing methods harness visual and temporal information separately, i.e., first using visual features with classifiers to predict each frame, and then using temporal dependencies to refine the results. In this way, visual features are unable to play a role in the temporal model and therefore such a scheme hardly benefits from the Spatio-Temporal information. Third, due to the above-mentioned two reasons, we analyze and find that it would be difficult for previous methods to sensitively identify and locate the transition frames while recognizing which is very important to achieve accurate and consistent workflow recognition results. \cite{SV-RCNet}
    \item \textit{Significance of this paper:}\\
    There are three main contributions from this paper. First, this paper proposed for the first time to use a deep neural network to extract visual features from the video frames. The ResNet makes it possible to optimize a much deeper network by embedding the identity transformation into the network through residual blocks. Using the ResNet as a spatial feature extractor, the SV-RCNet is able to find more discriminative features compared with models of shallow CNN. Second, instead of dealing with spatial and temporal features separately, SV-RCNet integrates ResNet and LSTM to form a novel recurrent convolutional architecture in order to take full advantage of the complementary information of visual and temporal features. LSTM is a direct improvement on the top of recurrent neural network (RNN), LSTM uses gates to generate “cell states” to aid the gradient flow and alleviate vanishing gradient. LSTM is designed to avoid long-term dependency problems and makes the training of long sequential data possible. SV-RCNet integrates the ResNet and the LSTM network, so that they are jointly trained in an end-to-end manner to generate high-level features that encode both spatial (visual) and temporal information. Particularly, the Spatio-temporal features learned by SV-RCNet are sensitive to motions in surgical videos and can precisely identify the phase transition frames. Third, considering that the results produced from SV-RCNet are transition-sensitive and the surgical videos are well-structured, another simple yet effective scheme called prior knowledge inference (PKI) is proposed to refine the SV-RCNet output. The PKI strategy is tailored to make use of the natural characteristics of surgical videos and can greatly improve recognition accuracy. 
   \item \textit{Results and problems:}\\
  SV-RCNet was the state-of-the-art model in surgical video segmentation in terms of performance in both Cholec80 and MICCAI M2CAI workflow Challenge. However, there are still drawbacks inherited in LSTMs, which retain the memory of a limited sequence, that cannot span minutes or hours, which is the average duration of surgery. Thus, the temporal information must be present in a slow, sequential way and prohibits inference parallelization, which would be beneficial for integration in an online OR scenario. 
\end{itemize}

\bibliography{bibfile}
\end{document}